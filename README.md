# Obesity ML Project - MLOps con DVC y Docker

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![DVC](https://img.shields.io/badge/DVC-3.30-orange.svg)](https://dvc.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8-blue.svg)](https://mlflow.org/)

Proyecto MLOps del **Equipo 52** para clasificaci√≥n de niveles de obesidad utilizando orquestaci√≥n con **DVC** y contenedores **Docker**.

> üìö **[√çndice Completo de Documentaci√≥n](DOCUMENTATION_INDEX.md)** - Navega toda la documentaci√≥n del proyecto

## üéØ Caracter√≠sticas Principales

- **Pipeline Orquestado con DVC**: Automatizaci√≥n completa del flujo ML (EDA ‚Üí Preprocessing ‚Üí Training ‚Üí Evaluation)
- **Versionado desde Docker**: Control de versiones de datos y modelos directamente en contenedores
- **Configuraci√≥n Centralizada**: Par√°metros y configuraciones en archivos YAML
- **Tracking con MLflow**: Seguimiento de experimentos y m√©tricas
- **Docker Compose**: M√∫ltiples servicios para diferentes tareas del pipeline

## üöÄ Inicio R√°pido

### 1. Prerequisitos

- Docker y Docker Compose instalados
- Credenciales de AWS S3 (o alternativa: GCS, Azure, local)
- Git configurado

### 2. Configuraci√≥n

```bash
# Clonar el repositorio
git clone <repository-url>
cd Fase-2_Equipo52

# Configurar variables de entorno
cp config/docker.env.template .env

# Editar .env con tus credenciales
# Ejemplo m√≠nimo requerido:
# AWS_ACCESS_KEY_ID=tu_key
# AWS_SECRET_ACCESS_KEY=tu_secret
# DVC_REMOTE_URL=s3://tu-bucket/dvc-storage
```

### 3. Ejecutar Pipeline Completo

```bash
# Construir y ejecutar el pipeline completo con DVC
docker-compose up dvc-pipeline

# Ver los resultados
docker-compose run --rm shell dvc metrics show
```

### 4. Ver Experimentos en MLflow

```bash
# Iniciar servidor MLflow
docker-compose up -d mlflow

# Acceder a http://localhost:5001
```

## üìÅ Estructura del Proyecto

```
Fase-2_Equipo52/
‚îú‚îÄ‚îÄ config/                      # üìù Configuraciones centralizadas
‚îÇ   ‚îú‚îÄ‚îÄ params.yaml             # Par√°metros del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ dvc_config.yaml         # Configuraci√≥n de DVC
‚îÇ   ‚îî‚îÄ‚îÄ docker.env.template     # Template de variables de entorno
‚îÇ
‚îú‚îÄ‚îÄ dvc.yaml                    # üîÑ Definici√≥n del pipeline DVC
‚îú‚îÄ‚îÄ docker-compose.yml          # üê≥ Orquestaci√≥n de servicios
‚îú‚îÄ‚îÄ Dockerfile                  # üê≥ Imagen Docker del proyecto
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ interim/                # Datos procesados
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Datos finales
‚îÇ
‚îú‚îÄ‚îÄ models/                     # ü§ñ Modelos entrenados
‚îú‚îÄ‚îÄ reports/                    # üìä Reportes y visualizaciones
‚îÇ   ‚îú‚îÄ‚îÄ figures/
‚îÇ   ‚îî‚îÄ‚îÄ metrics/
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # üîß Scripts de ejecuci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ dvc_docker_setup.sh    # Configurar DVC en Docker
‚îÇ   ‚îú‚îÄ‚îÄ dvc_run_pipeline.sh    # Ejecutar pipeline completo
‚îÇ   ‚îú‚îÄ‚îÄ run_eda.py             # An√°lisis exploratorio
‚îÇ   ‚îî‚îÄ‚îÄ run_ml.py              # Entrenamiento de modelos
‚îÇ
‚îú‚îÄ‚îÄ src/                        # üíª C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ data/                   # Procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Modelos y entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ visualization/          # Visualizaciones
‚îÇ
‚îî‚îÄ‚îÄ tests/                      # üß™ Tests unitarios
```

## üîß Servicios Docker Disponibles

### `dvc-pipeline` (Principal)
Ejecuta el pipeline completo orquestado por DVC:
```bash
docker-compose up dvc-pipeline
```

### `dvc-pull`
Descarga datos/modelos versionados:
```bash
docker-compose up dvc-pull
```

### `dvc-push`
Sube datos/modelos al remote storage:
```bash
docker-compose up dvc-push
```

### `mlflow`
Servidor MLflow UI:
```bash
docker-compose up -d mlflow
# http://localhost:5001
```

### `api`
**üöÄ NUEVO**: API de Inferencia FastAPI:
```bash
docker-compose up api
# http://localhost:8000/docs
```

Endpoints disponibles:
- `POST /predict` - Predicci√≥n individual
- `POST /predict/batch` - Predicci√≥n por lote
- `GET /health` - Health check
- `GET /model/info` - Informaci√≥n del modelo

**Ver documentaci√≥n completa**: [api/README.md](api/README.md)

### `shell`
Shell interactivo para desarrollo:
```bash
docker-compose run --rm shell

# Comandos √∫tiles:
dvc status          # Estado del pipeline
dvc dag             # Visualizar DAG
dvc metrics show    # Ver m√©tricas
```

### `test`
Ejecutar tests unitarios:
```bash
docker-compose up test
```

### `simulate-drift`
Simular data drift (genera dataset con cambios en distribuciones):
```bash
docker-compose run --rm simulate-drift
```

### `detect-drift`
Detectar data drift y comparar performance:
```bash
docker-compose run --rm detect-drift
```

### `visualize-drift`
Generar visualizaciones de drift detection:
```bash
docker-compose run --rm visualize-drift
```

## üìä Pipeline DVC

El pipeline est√° definido en `dvc.yaml` y consta de 5 etapas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   EDA   ‚îÇ -> ‚îÇ Preprocessing‚îÇ -> ‚îÇ  Train  ‚îÇ -> ‚îÇ Evaluate ‚îÇ -> ‚îÇ Visualize ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Etapas del Pipeline

1. **EDA**: Limpieza y an√°lisis exploratorio de datos
2. **Preprocess**: Feature engineering (BMI), encoding, scaling
3. **Train**: Entrenamiento de m√∫ltiples modelos con validaci√≥n cruzada
4. **Evaluate**: Evaluaci√≥n del mejor modelo en datos de prueba
5. **Visualize**: Generaci√≥n de reportes y visualizaciones

## üéõÔ∏è Configuraci√≥n de Par√°metros

Todos los par√°metros est√°n centralizados en `config/params.yaml`:

```yaml
data:
  test_size: 0.2
  random_state: 42

models:
  algorithms:
    - logistic_regression
    - random_forest
    - xgboost

training:
  cv_folds: 5
  scoring: accuracy
```

Modificar estos par√°metros re-ejecuta solo las etapas afectadas (gracias a DVC).

## üîê Versionado de Datos con DVC

### Agregar Datos a DVC

```bash
docker-compose run --rm shell bash scripts/dvc_version.sh add-data
```

### Subir al Remote Storage

```bash
docker-compose up dvc-push
```

### Descargar desde Remote Storage

```bash
docker-compose up dvc-pull
```

## üìà Monitoreo y M√©tricas

### Ver M√©tricas con DVC

```bash
docker-compose run --rm shell dvc metrics show
```

### Ver Experimentos en MLflow

```bash
docker-compose up -d mlflow
# Abrir http://localhost:5001
```

### Comparar Versiones

```bash
docker-compose run --rm shell dvc metrics diff
```

## üß™ Testing

```bash
# Ejecutar todos los tests
docker-compose up test

# Ejecutar tests espec√≠ficos
docker-compose run --rm test pytest tests/test_ml_pipeline.py -v

# Tests del API
docker-compose run --rm test pytest tests/test_api.py -v
```

## üöÄ API de Inferencia (FastAPI)

### Caracter√≠sticas

El proyecto incluye una **API REST completa** construida con **FastAPI** para realizar predicciones en tiempo real:

- ‚úÖ **Endpoints RESTful** para predicci√≥n individual (`POST /predict`) y por lote (`POST /predict/batch`)
- ‚úÖ **Validaci√≥n autom√°tica** de entrada con Pydantic
- ‚úÖ **Documentaci√≥n interactiva** con Swagger/OpenAPI en `/docs`
- ‚úÖ **Health checks** para monitoring en `GET /health`
- ‚úÖ **Informaci√≥n del modelo** en `GET /model/info`
- ‚úÖ **Handling de errores** robusto con respuestas JSON
- ‚úÖ **CORS habilitado** para acceso desde cualquier origen
- ‚úÖ **Logging completo** de predicciones

### Inicio R√°pido

```bash
# Opci√≥n 1: Levantar el servicio API con Docker Compose
docker-compose up api

# Opci√≥n 2: Ejecutar localmente (si tienes las dependencias instaladas)
cd Fase-2_Equipo52
pip install -r requirements.txt
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

**Acceder a la API:**
- Documentaci√≥n Swagger: http://localhost:8000/docs
- Documentaci√≥n ReDoc: http://localhost:8000/redoc
- API ra√≠z: http://localhost:8000/

### Endpoints Disponibles

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| `GET` | `/` | Informaci√≥n de la API |
| `GET` | `/health` | Health check del servicio |
| `GET` | `/model/info` | Informaci√≥n del modelo (versi√≥n, accuracy, clases) |
| `POST` | `/predict` | Predicci√≥n individual |
| `POST` | `/predict/batch` | Predicci√≥n por lote (m√∫ltiples muestras) |

### Ejemplo de Uso: Predicci√≥n Individual

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "Age": 25.0,
    "Height": 1.75,
    "Weight": 85.0,
    "Gender": "Male",
    "FCVC": 2.0,
    "NCP": 3.0,
    "CAEC": "Sometimes",
    "CH2O": 2.5,
    "FAF": 1.5,
    "TUE": 1.0,
    "MTRANS": "Automobile",
    "family_history_with_overweight": "yes",
    "FAVC": "no",
    "SCC": "no"
  }'
```

**Respuesta esperada:**

```json
{
  "prediction": "Overweight_Level_II",
  "confidence": null,
  "features_received": {
    "Age": 25.0,
    "Height": 1.75,
    "Weight": 85.0,
    "Gender": "Male",
    "FCVC": 2.0,
    "NCP": 3.0,
    "CAEC": "Sometimes",
    "CH2O": 2.5,
    "FAF": 1.5,
    "TUE": 1.0,
    "MTRANS": "Automobile",
    "family_history_with_overweight": "yes",
    "FAVC": "no",
    "SCC": "no"
  },
  "model_name": "XGBoost_SMOTE",
  "model_version": "1.0.0"
}
```

### Ejemplo: Predicci√≥n Batch

```bash
curl -X POST "http://localhost:8000/predict/batch" \
  -H "Content-Type: application/json" \
  -d '{
    "samples": [
      {
        "Age": 25.0,
        "Height": 1.75,
        "Weight": 85.0,
        "Gender": "Male",
        "FCVC": 2.0,
        "NCP": 3.0,
        "CAEC": "Sometimes",
        "CH2O": 2.5,
        "FAF": 1.5,
        "TUE": 1.0,
        "MTRANS": "Automobile",
        "family_history_with_overweight": "yes",
        "FAVC": "no",
        "SCC": "no"
      }
    ]
  }'
```

### Health Check

```bash
curl http://localhost:8000/health
```

**Respuesta:**

```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0",
  "timestamp": "2024-01-15T10:30:00.123456"
}
```

### Informaci√≥n del Modelo

```bash
curl http://localhost:8000/model/info
```

**Respuesta:**

```json
{
  "model_name": "XGBoost_SMOTE",
  "model_version": "1.0.0",
  "accuracy": 0.975,
  "classes": [
    "Insufficient_Weight",
    "Normal_Weight",
    "Overweight_Level_I",
    "Overweight_Level_II",
    "Obesity_Type_I",
    "Obesity_Type_II",
    "Obesity_Type_III"
  ],
  "features_required": 13,
  "deployment_date": "2024-01-15"
}
```

### Versionado del Modelo y Artefactos

```
Modelo guardado en:
  models/best_pipeline.joblib (artefacto principal)
  models/model_metadata.joblib (metadata)

Informaci√≥n de versi√≥n:
  Versi√≥n del modelo: v1.0.0
  Framework: XGBoost + SMOTE
  Accuracy: ~97%
  Test size: 20%
```

### Schema de Validaci√≥n (Pydantic)

El endpoint `/predict` valida autom√°ticamente:

```python
class ObesityFeatures(BaseModel):
    Age: float  # 14-100 a√±os
    Height: float  # 1.0-2.5 metros
    Weight: float  # 20-200 kg
    Gender: str  # "Female" o "Male"
    FCVC: float  # 1-3 (Frecuencia consumo verduras)
    NCP: float  # 1-4 (N√∫mero comidas principales)
    CAEC: str  # "no", "Sometimes", "Frequently", "Always"
    CH2O: float  # 1-3 (Consumo agua diario)
    FAF: float  # 0-3 (Frecuencia actividad f√≠sica)
    TUE: float  # 0-2 (Tiempo usando tecnolog√≠a)
    MTRANS: str  # Tipo de transporte
    family_history_with_overweight: str  # "yes" o "no"
    FAVC: str  # "yes" o "no" (Comida cal√≥rica frecuente)
    SCC: str  # "yes" o "no" (Bebidas cal√≥ricas)
```

Errores de validaci√≥n retornan `HTTP 422` con detalles espec√≠ficos.

## üîç Data Drift Detection

El proyecto incluye un **sistema completo de detecci√≥n de data drift** para monitorear cambios en la distribuci√≥n de datos que afectan el desempe√±o del modelo.

### Caracter√≠sticas

- ‚úÖ **PSI (Population Stability Index)**: Detecta cambios en distribuciones de features
- ‚úÖ **Tests Estad√≠sticos**: Comparaci√≥n con KS test y Mann-Whitney U
- ‚úÖ **Monitoreo de Performance**: Compara m√©tricas (Accuracy, Precision, Recall, F1)
- ‚úÖ **Sistema de Alertas**: Umbrales configurables (PSI > 0.2, Accuracy degradation > 5%)
- ‚úÖ **Visualizaciones**: Gr√°ficos comparativos y heatmaps

### Flujo de Drift Detection

```bash
# 1. Simular drift (genera dataset con cambios controlados)
docker compose run --rm simulate-drift

# 2. Detectar drift y comparar performance
docker compose run --rm detect-drift

# 3. Generar visualizaciones
docker compose run --rm visualize-drift
```

### Resultados Generados

Despu√©s de ejecutar el flujo, encontrar√°s:

- **Dataset con drift**: `data/interim/dataset_with_drift.csv`
- **Reporte JSON**: `reports/drift/drift_report.json`
- **Alertas**: `reports/drift/drift_alerts.txt`
- **Visualizaciones**:
  - `reports/figures/10_drift_distributions.png` - Distribuciones comparadas
  - `reports/figures/11_drift_performance_comparison.png` - Comparaci√≥n de m√©tricas
  - `reports/figures/12_drift_psi_heatmap.png` - Heatmap de PSI

### Umbrales y Alertas

El sistema utiliza los siguientes umbrales profesionales:

- **PSI > 0.2**: Alerta de drift significativo en feature
- **PSI > 0.5**: Alerta cr√≠tica de drift
- **Accuracy degradation > 5%**: Warning de degradaci√≥n
- **Accuracy degradation > 10%**: Alerta cr√≠tica (recomienda retrain)

### Interpretaci√≥n de Resultados

**Ejemplo de resultados:**
- Baseline Accuracy: 99.3%
- Current Accuracy: 65.4%
- **Degradaci√≥n: -34.1%** ‚Üí Alerta CR√çTICA

**¬øEs malo que baje el accuracy?**
No, es **esperado y demuestra que el sistema funciona**. La degradaci√≥n indica que:
1. Los datos han cambiado (drift detectado)
2. El modelo necesita retrenarse con datos actuales
3. El sistema de monitoreo est√° funcionando correctamente

**Ver resumen completo**: [RESUMEN_DRIFT_DETECTION.md](RESUMEN_DRIFT_DETECTION.md)

## üê≥ Comandos Docker Directos

Adem√°s de `docker-compose`, puedes usar comandos directos de Docker:

### Construir Imagen

```bash
# Construir imagen del servicio
docker build -t ml-service:latest .

# Construir con tag versionado
docker build -t ml-service:v1.0.0 .
docker build -t ml-service:v1.0.0 -t ml-service:latest .
```

### Ejecutar Contenedor

```bash
# Ejecutar contenedor del servicio API
docker run -p 8000:8000 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/data:/app/data \
  --env-file .env \
  ml-service:latest

# Ejecutar con tag espec√≠fico
docker run -p 8000:8000 ml-service:v1.0.0
```

### Publicar en DockerHub (Opcional)

```bash
# Login a DockerHub
docker login

# Tag para DockerHub
docker tag ml-service:latest tu-usuario/ml-service:v1.0.0
docker tag ml-service:latest tu-usuario/ml-service:latest

# Push a DockerHub
docker push tu-usuario/ml-service:v1.0.0
docker push tu-usuario/ml-service:latest
```

### Tags Versionados Recomendados

- `v1.0.0` - Versi√≥n inicial
- `v1.1.0` - Nuevas features
- `v1.0.1` - Bug fixes
- `latest` - √öltima versi√≥n estable

## üìö Documentaci√≥n Adicional

- [Gu√≠a Completa Docker + DVC](DOCKER_DVC_GUIDE.md)
- [FAQ - Preguntas Frecuentes](FAQ.md)
- [Checklist de Setup](SETUP_CHECKLIST.md)
- [Arquitectura del Sistema](ARCHITECTURE.md)

## üîÑ Flujo de Trabajo T√≠pico

### Desarrollo de Nuevas Features

1. Modificar c√≥digo o par√°metros
2. Probar en shell interactivo: `docker-compose run --rm shell`
3. Ejecutar pipeline: `docker-compose up dvc-pipeline`
4. Versionar cambios: `docker-compose up dvc-push`

### Reproducir Experimentos

1. Pull de datos: `docker-compose up dvc-pull`
2. Ejecutar pipeline: `docker-compose up dvc-pipeline`
3. Ver m√©tricas: `docker-compose run --rm shell dvc metrics show`

## üêõ Troubleshooting

### DVC Remote no configurado

```bash
# Verificar .env
cat .env | grep DVC_REMOTE

# Re-configurar
docker-compose run --rm shell bash scripts/dvc_docker_setup.sh
```

### Reconstruir contenedores

```bash
docker-compose build --no-cache
docker-compose up dvc-pipeline
```

## ü§ù Equipo

**Equipo 52 - Proyecto MLOps**

- Clasificaci√≥n de Niveles de Obesidad
- Fase 2: Orquestaci√≥n con DVC y Docker

## üìÑ Licencia

Este proyecto es parte del curso de MLOps y est√° disponible para fines educativos.

## üîó Referencias

- [DVC Documentation](https://dvc.org/doc)
- [Docker Documentation](https://docs.docker.com/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Scikit-learn](https://scikit-learn.org/)
