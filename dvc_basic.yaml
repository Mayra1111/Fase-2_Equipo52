# DVC Pipeline - BASIC (Without Drift Detection)
# Runs: EDA -> Preprocess -> Train -> Evaluate -> Visualize
# Use with: dvc repro -f dvc_basic.yaml

stages:
  # Stage 1: Análisis Exploratorio de Datos (EDA)
  eda:
    cmd: python scripts/run_eda.py --input ${data.raw_path} --output ${data.interim_path}
    deps:
      - scripts/run_eda.py
      - data/raw/obesity_estimation_modified.csv
      - pipelines/eda_pipeline.py
      - src/data/data_loader.py
      - src/data/data_cleaner.py
    params:
      - config/params.yaml:
          - data.raw_path
          - data.interim_path
          - data.random_state
    outs:
      - ${data.interim_path}:
          cache: true
          persist: true
    desc: "Limpieza y análisis exploratorio de datos, generación de dataset limpio"

  # Stage 2: Preprocesamiento y creación de features
  preprocess:
    cmd: python scripts/run_preprocess.py
    deps:
      - scripts/run_preprocess.py
      - ${data.interim_path}
      - pipelines/ml_pipeline.py
      - src/models/data_preprocessor.py
      - config/params.yaml
    params:
      - config/params.yaml:
          - data.interim_path
          - data.test_size
          - data.random_state
          - preprocessing.create_bmi
          - preprocessing.handle_outliers
          - preprocessing.scale_features
    desc: "Preprocesamiento de datos, feature engineering (BMI), encoding y scaling"

  # Stage 3: Entrenamiento de modelos
  train:
    cmd: python scripts/run_ml.py --input ${data.interim_path} --output ${models.output_dir} --experiment ${mlflow.experiment_name}
    deps:
      - scripts/run_ml.py
      - ${data.interim_path}
      - pipelines/ml_pipeline.py
      - src/models/data_preprocessor.py
      - src/models/model_trainer.py
      - config/params.yaml
    params:
      - config/params.yaml:
          - data.interim_path
          - data.test_size
          - data.random_state
          - models.output_dir
          - models.algorithms
          - training.cross_validation
          - training.cv_folds
          - training.scoring
          - mlflow.experiment_name
    outs:
      - ${models.output_dir}/best_pipeline.joblib:
          cache: true
          persist: true
      - ${models.output_dir}/model_metadata.joblib:
          cache: true
          persist: true
    desc: "Entrenamiento de múltiples modelos, selección del mejor con validación cruzada"

  # Stage 4: Evaluación del modelo
  evaluate:
    cmd: python scripts/run_evaluate.py
    deps:
      - scripts/run_evaluate.py
      - ${models.output_dir}/best_pipeline.joblib
      - ${models.output_dir}/model_metadata.joblib
      - config/params.yaml
    params:
      - config/params.yaml:
          - evaluation.metrics
          - evaluation.generate_plots
          - evaluation.confusion_matrix
    outs:
      - reports/metrics/evaluation_metrics.json:
          cache: false
    desc: "Evaluación del mejor modelo en datos de prueba, generación de métricas y gráficos"

  # Stage 5: Generación de visualizaciones finales
  visualize:
    cmd: python scripts/generate_visualizations.py --input ${data.interim_path} --output-dir ${reports.figures_dir}
    deps:
      - scripts/generate_visualizations.py
      - ${data.interim_path}
      - src/visualization/eda_visualizer.py
    params:
      - config/params.yaml:
          - data.interim_path
          - reports.figures_dir
          - reports.format
          - reports.dpi
    outs:
      - reports/figures/01_dataset_overview.png:
          cache: false
      - reports/figures/02_numeric_distributions.png:
          cache: false
      - reports/figures/06_correlation_matrix.png:
          cache: false
    desc: "Generación de visualizaciones y reportes finales del proyecto"

vars:
  - config/params.yaml
